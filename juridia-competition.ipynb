{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90488,"databundleVersionId":10564594,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:31:47.368813Z","iopub.execute_input":"2024-12-23T21:31:47.369151Z","iopub.status.idle":"2024-12-23T21:31:52.164658Z","shell.execute_reply.started":"2024-12-23T21:31:47.369123Z","shell.execute_reply":"2024-12-23T21:31:52.163878Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.44.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.4.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.24.7)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.3.1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:34:06.119135Z","iopub.execute_input":"2024-12-23T21:34:06.119474Z","iopub.status.idle":"2024-12-23T21:34:09.201961Z","shell.execute_reply.started":"2024-12-23T21:34:06.119448Z","shell.execute_reply":"2024-12-23T21:34:09.201114Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\nimport transformers\nfrom sentence_transformers import SentenceTransformer\nimport torch \nimport torch.nn.functional as F\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:31:53.503245Z","iopub.execute_input":"2024-12-23T21:31:53.503670Z","iopub.status.idle":"2024-12-23T21:32:03.754397Z","shell.execute_reply.started":"2024-12-23T21:31:53.503634Z","shell.execute_reply":"2024-12-23T21:32:03.753485Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from transformers import logging\n\n# Suppress tokenizer warnings\nlogging.set_verbosity_error()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:32:03.755461Z","iopub.execute_input":"2024-12-23T21:32:03.756026Z","iopub.status.idle":"2024-12-23T21:32:03.759969Z","shell.execute_reply.started":"2024-12-23T21:32:03.755987Z","shell.execute_reply":"2024-12-23T21:32:03.759132Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Data collection and preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Uploading the data set","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/juridia-hackhaton-relevance-competition/train.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:32:31.486259Z","iopub.execute_input":"2024-12-23T21:32:31.486527Z","iopub.status.idle":"2024-12-23T21:32:31.637643Z","shell.execute_reply.started":"2024-12-23T21:32:31.486507Z","shell.execute_reply":"2024-12-23T21:32:31.636977Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:08:25.297027Z","iopub.execute_input":"2024-12-23T00:08:25.297346Z","iopub.status.idle":"2024-12-23T00:08:25.312442Z","shell.execute_reply.started":"2024-12-23T00:08:25.297322Z","shell.execute_reply":"2024-12-23T00:08:25.311610Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Je suis travailleur salarié(e). Puis-je refuse...   \n1  Je suis travailleur salarié(e). Puis-je refuse...   \n2  Je suis travailleur salarié(e). Puis-je refuse...   \n3  Je suis travailleur salarié(e). Puis-je refuse...   \n4  Je suis travailleur salarié(e). Puis-je refuse...   \n\n                                             article  \n0  Les dispositions du présent titre s'appliquent...  \n1  Les travailleuses visées à l'article X.5-1, al...  \n2  Lorsqu'une personne occupe des domestiques et ...  \n3  L'employeur effectue l'analyse des risques vis...  \n4  Les résultats de ladite analyse des risques et...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Je suis travailleur salarié(e). Puis-je refuse...</td>\n      <td>Les dispositions du présent titre s'appliquent...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Je suis travailleur salarié(e). Puis-je refuse...</td>\n      <td>Les travailleuses visées à l'article X.5-1, al...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Je suis travailleur salarié(e). Puis-je refuse...</td>\n      <td>Lorsqu'une personne occupe des domestiques et ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Je suis travailleur salarié(e). Puis-je refuse...</td>\n      <td>L'employeur effectue l'analyse des risques vis...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Je suis travailleur salarié(e). Puis-je refuse...</td>\n      <td>Les résultats de ladite analyse des risques et...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:32:03.761430Z","iopub.execute_input":"2024-12-23T21:32:03.761737Z","iopub.status.idle":"2024-12-23T21:32:03.852841Z","shell.execute_reply.started":"2024-12-23T21:32:03.761709Z","shell.execute_reply":"2024-12-23T21:32:03.851921Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import random\n\ndef generate_pairs(data):\n    pairs = []\n    for i, row in data.iterrows():\n        # Positive pair\n        pairs.append({\"question\": row[\"question\"], \"article\": row[\"article\"], \"label\": 1})\n        \n        # Negative pair\n        random_answer = data.loc[random.randint(0, len(data) - 1), \"article\"]\n        if random_answer != row[\"article\"]:  # Avoid accidental positives\n            pairs.append({\"question\": row[\"question\"], \"article\": random_answer, \"label\": 0})\n    \n    return pairs\n\n# Generate pairs\npairs = generate_pairs(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:32:33.838173Z","iopub.execute_input":"2024-12-23T21:32:33.838441Z","iopub.status.idle":"2024-12-23T21:32:34.223173Z","shell.execute_reply.started":"2024-12-23T21:32:33.838421Z","shell.execute_reply":"2024-12-23T21:32:34.222246Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"pairs[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:08:31.956854Z","iopub.execute_input":"2024-12-23T00:08:31.957129Z","iopub.status.idle":"2024-12-23T00:08:31.962321Z","shell.execute_reply.started":"2024-12-23T00:08:31.957109Z","shell.execute_reply":"2024-12-23T00:08:31.961625Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'question': 'Je suis travailleur salarié(e). Puis-je refuser de faire des heures supplémentaires ou de travailler de nuit ?',\n 'article': \"Les dispositions du présent titre s'appliquent aux employeurs et aux travailleuses visés à l'article 1er de la loi sur le travail du 16 mars 1971.Elles s'appliquent notamment aux travailleuses visées à l'alinéa 1er, pendant la grossesse, après l'accouchement et pendant l'allaitement.\",\n 'label': 1}"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Model and Tokenizer Setup","metadata":{}},{"cell_type":"code","source":"from transformers import CamembertTokenizer\n\n# Initialize tokenizer\ntokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n\ndef preprocess_data(pairs, tokenizer, max_length=256):\n    inputs = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\n    for pair in pairs:\n        # Tokenize question and article\n        tokenized = tokenizer(\n            pair[\"question\"], \n            pair[\"article\"], \n            max_length=max_length, \n            truncation=True, \n            padding=\"max_length\", \n            return_tensors=\"pt\"\n        )\n        inputs[\"input_ids\"].append(tokenized[\"input_ids\"].squeeze(0))\n        inputs[\"attention_mask\"].append(tokenized[\"attention_mask\"].squeeze(0))\n        inputs[\"labels\"].append(pair[\"label\"])\n    return inputs\n\n# Preprocess the pairs\nprocessed_data = preprocess_data(pairs, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:32:36.468476Z","iopub.execute_input":"2024-12-23T21:32:36.468752Z","iopub.status.idle":"2024-12-23T21:32:53.029678Z","shell.execute_reply.started":"2024-12-23T21:32:36.468733Z","shell.execute_reply":"2024-12-23T21:32:53.028971Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass RelevanceDataset(Dataset):\n    def __init__(self, inputs):\n        self.input_ids = inputs[\"input_ids\"]\n        self.attention_mask = inputs[\"attention_mask\"]\n        self.labels = inputs[\"labels\"]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": self.input_ids[idx],\n            \"attention_mask\": self.attention_mask[idx],\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float)\n        }\n\n# Create dataset and dataloader\ndataset = RelevanceDataset(processed_data)\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:32:57.280381Z","iopub.execute_input":"2024-12-23T21:32:57.280696Z","iopub.status.idle":"2024-12-23T21:32:57.286466Z","shell.execute_reply.started":"2024-12-23T21:32:57.280670Z","shell.execute_reply":"2024-12-23T21:32:57.285496Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import CamembertModel\n\nclass RelevanceModel(nn.Module):\n    def __init__(self, pretrained_model_name=\"camembert-base\"):\n        super(RelevanceModel, self).__init__()\n        # Embedding layer (Pretrained Language Model)\n        self.embedding_model = CamembertModel.from_pretrained(pretrained_model_name)\n        self.hidden_size = 768  # CamemBERT hidden size\n        # Dense layer\n        self.dense = nn.Linear(self.hidden_size, 256)\n        self.dropout = nn.Dropout(0.2)\n        # Normalization layer\n        self.normalization = nn.LayerNorm(256)\n        # Output layer (raw logits)\n        self.output = nn.Linear(256, 1)\n\n    def forward(self, input_ids, attention_mask):\n        # Extract embeddings from the pretrained model\n        outputs = self.embedding_model(input_ids=input_ids, attention_mask=attention_mask)\n        cls_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token embedding\n        \n        # Pass through dense and normalization layers\n        dense_output = self.dense(cls_embedding)\n        dense_output = self.dropout(dense_output)\n        normalized_output = self.normalization(dense_output)\n        \n        # Return raw logits (no sigmoid here)\n        logits = self.output(normalized_output)\n        return logits  # raw logits, to be processed by BCEWithLogitsLoss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:33:00.619562Z","iopub.execute_input":"2024-12-23T21:33:00.619835Z","iopub.status.idle":"2024-12-23T21:33:00.630321Z","shell.execute_reply.started":"2024-12-23T21:33:00.619816Z","shell.execute_reply":"2024-12-23T21:33:00.629569Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model = RelevanceModel()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:19:13.358512Z","iopub.execute_input":"2024-12-23T00:19:13.358823Z","iopub.status.idle":"2024-12-23T00:19:13.589730Z","shell.execute_reply.started":"2024-12-23T00:19:13.358799Z","shell.execute_reply":"2024-12-23T00:19:13.589088Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:19:15.165493Z","iopub.execute_input":"2024-12-23T00:19:15.165988Z","iopub.status.idle":"2024-12-23T00:19:15.336664Z","shell.execute_reply.started":"2024-12-23T00:19:15.165946Z","shell.execute_reply":"2024-12-23T00:19:15.335981Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Safe for mixed precision\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:19:17.352090Z","iopub.execute_input":"2024-12-23T00:19:17.352373Z","iopub.status.idle":"2024-12-23T00:19:17.357485Z","shell.execute_reply.started":"2024-12-23T00:19:17.352352Z","shell.execute_reply":"2024-12-23T00:19:17.356558Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"from torch.nn import DataParallel\nfrom transformers import CamembertTokenizer\nfrom torch.cuda.amp import autocast, GradScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:09:06.057314Z","iopub.execute_input":"2024-12-23T00:09:06.057714Z","iopub.status.idle":"2024-12-23T00:09:06.061832Z","shell.execute_reply.started":"2024-12-23T00:09:06.057662Z","shell.execute_reply":"2024-12-23T00:09:06.060938Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(f\"Using {torch.cuda.device_count()} GPUs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:09:06.680834Z","iopub.execute_input":"2024-12-23T00:09:06.681105Z","iopub.status.idle":"2024-12-23T00:09:06.722936Z","shell.execute_reply.started":"2024-12-23T00:09:06.681086Z","shell.execute_reply":"2024-12-23T00:09:06.722273Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(next(model.parameters()).device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:09:08.638301Z","iopub.execute_input":"2024-12-23T00:09:08.638623Z","iopub.status.idle":"2024-12-23T00:09:08.643217Z","shell.execute_reply.started":"2024-12-23T00:09:08.638598Z","shell.execute_reply":"2024-12-23T00:09:08.642405Z"}},"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Model training ","metadata":{}},{"cell_type":"code","source":"import tqdm as tqdm\nscaler = GradScaler()\nepochs = 10\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(dataloader, desc=f\"Training Epoch {epoch+1}\"):\n        # Move the batch tensors to the same device as the model\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        optimizer.zero_grad()\n\n        # Mixed precision forward pass\n        with autocast():\n            logits = model(input_ids, attention_mask).squeeze()  # Ensure all tensors are on the same device\n            loss = criterion(logits, labels)  # Use logits directly\n\n        # Backward pass and optimizer step\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(dataloader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:19:20.898740Z","iopub.execute_input":"2024-12-23T00:19:20.899032Z","iopub.status.idle":"2024-12-23T00:53:50.150414Z","shell.execute_reply.started":"2024-12-23T00:19:20.899011Z","shell.execute_reply":"2024-12-23T00:53:50.149129Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-32-2b79984c6bf4>:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\nTraining Epoch 1:   0%|          | 0/723 [00:00<?, ?it/s]<ipython-input-32-2b79984c6bf4>:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nTraining Epoch 1: 100%|██████████| 723/723 [03:22<00:00,  3.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 0.43546830918408036\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 723/723 [03:28<00:00,  3.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.2482410333509638\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 723/723 [03:27<00:00,  3.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.19609222023452877\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4: 100%|██████████| 723/723 [03:27<00:00,  3.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 0.17088880258667724\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5: 100%|██████████| 723/723 [03:27<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 0.1490711303734392\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6: 100%|██████████| 723/723 [03:27<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Loss: 0.13932970282814902\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7: 100%|██████████| 723/723 [03:27<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Loss: 0.13464038814340729\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8: 100%|██████████| 723/723 [03:26<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Loss: 0.12157566955600985\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9: 100%|██████████| 723/723 [03:26<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Loss: 0.12138241049617833\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10: 100%|██████████| 723/723 [03:26<00:00,  3.50it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Loss: 0.11567404688294734\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Save the model's state_dict\ntorch.save(model.state_dict(), \"relevance_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T00:57:04.113269Z","iopub.execute_input":"2024-12-23T00:57:04.113564Z","iopub.status.idle":"2024-12-23T00:57:04.745596Z","shell.execute_reply.started":"2024-12-23T00:57:04.113534Z","shell.execute_reply":"2024-12-23T00:57:04.744939Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"# testing the model output","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import CamembertTokenizer\nfrom torch.nn.functional import sigmoid\n\n# Load the trained model\n#model = RelevanceModel(pretrained_model_name=\"camembert-base\")\n# model.load_state_dict(torch.load(\"model_checkpoint.pth\"))  # Load trained weights\nmodel.eval()  # Set model to evaluation mode\n\n# Load tokenizer\ntokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n\n# Define the question and answer\nquestion = pairs[121]['question']\nanswer = pairs[121]['article']\nlabel = pairs[121]['label']\n\n# Preprocess the input\ndef preprocess_input(question, answer, tokenizer, max_length=256):\n    tokenized = tokenizer(\n        question,\n        answer,\n        max_length=max_length,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\"\n    )\n    return tokenized\n\n# Tokenize input\ninputs = preprocess_input(question, answer, tokenizer)\n\n# Move inputs to the appropriate device (e.g., GPU or CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninputs = {key: value.to(device) for key, value in inputs.items()}\nmodel.to(device)\n\n# Get the model's prediction\nwith torch.no_grad():\n    logits = model(inputs[\"input_ids\"], inputs[\"attention_mask\"]).squeeze()\n\n# Convert logits to probabilities\nrelevance_score = sigmoid(logits).item()  # Convert to a probability between 0.0 and 1.0\n\n# Print the relevance score\nprint(f\"Relevance Score: {relevance_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T01:04:12.572952Z","iopub.execute_input":"2024-12-23T01:04:12.573261Z","iopub.status.idle":"2024-12-23T01:04:13.164312Z","shell.execute_reply.started":"2024-12-23T01:04:12.573234Z","shell.execute_reply":"2024-12-23T01:04:13.163496Z"}},"outputs":[{"name":"stdout","text":"Relevance Score: 0.9979\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"# Generate relevance for the test.csv to be submit it","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/juridia-hackhaton-relevance-competition/test.csv')\ndf_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T21:31:37.838305Z","iopub.execute_input":"2024-12-23T21:31:37.838603Z","iopub.status.idle":"2024-12-23T21:31:37.901808Z","shell.execute_reply.started":"2024-12-23T21:31:37.838577Z","shell.execute_reply":"2024-12-23T21:31:37.901069Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               question  \\\n0     Quels sont les critères communaux d'insalubrité ?   \n1     A-t-on droit à l'allocation de naissance en ca...   \n2     A-t-on droit à l'allocation de naissance en ca...   \n3     Quels frais peut-on ajouter lors d'un recouvre...   \n4     Quels frais peut-on ajouter lors d'un recouvre...   \n...                                                 ...   \n1056                     A qui dois-je payer ma dette ?   \n1057  Je suis marié(e). On prend un logement en loca...   \n1058  Est-ce que je peux signer plusieurs baux de co...   \n1059  Je suis victime de violences conjugales. En ta...   \n1060  Je suis victime de violences conjugales. En ta...   \n\n                                                article    Id  \n0     Le bourgmestre statue sur le rapport d'enquête...     0  \n1     § 1er. Lorsqu'un enfant est décédé au moment d...     1  \n2     L'acte d'enfant sans vie mentionne :1° la date...     2  \n3     Dans les obligations qui se bornent au payemen...     3  \n4     § 1er. Le juge peut, d'office ou à la demande ...     4  \n...                                                 ...   ...  \n1056  Le payement doit être fait au créancier ou à q...  1056  \n1057  Chaque époux perçoit seul ses revenus et les a...  1057  \n1058  Baux de courte duréePar dérogation à l'article...  1058  \n1059  Dans les cas mentionnés aux articles 398 à 405...  1059  \n1060  Quiconque aura harcelé une personne alors qu'i...  1060  \n\n[1061 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>article</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Quels sont les critères communaux d'insalubrité ?</td>\n      <td>Le bourgmestre statue sur le rapport d'enquête...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A-t-on droit à l'allocation de naissance en ca...</td>\n      <td>§ 1er. Lorsqu'un enfant est décédé au moment d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A-t-on droit à l'allocation de naissance en ca...</td>\n      <td>L'acte d'enfant sans vie mentionne :1° la date...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Quels frais peut-on ajouter lors d'un recouvre...</td>\n      <td>Dans les obligations qui se bornent au payemen...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Quels frais peut-on ajouter lors d'un recouvre...</td>\n      <td>§ 1er. Le juge peut, d'office ou à la demande ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>A qui dois-je payer ma dette ?</td>\n      <td>Le payement doit être fait au créancier ou à q...</td>\n      <td>1056</td>\n    </tr>\n    <tr>\n      <th>1057</th>\n      <td>Je suis marié(e). On prend un logement en loca...</td>\n      <td>Chaque époux perçoit seul ses revenus et les a...</td>\n      <td>1057</td>\n    </tr>\n    <tr>\n      <th>1058</th>\n      <td>Est-ce que je peux signer plusieurs baux de co...</td>\n      <td>Baux de courte duréePar dérogation à l'article...</td>\n      <td>1058</td>\n    </tr>\n    <tr>\n      <th>1059</th>\n      <td>Je suis victime de violences conjugales. En ta...</td>\n      <td>Dans les cas mentionnés aux articles 398 à 405...</td>\n      <td>1059</td>\n    </tr>\n    <tr>\n      <th>1060</th>\n      <td>Je suis victime de violences conjugales. En ta...</td>\n      <td>Quiconque aura harcelé une personne alors qu'i...</td>\n      <td>1060</td>\n    </tr>\n  </tbody>\n</table>\n<p>1061 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def predict_relevance(model, tokenizer, question, article, device):\n    # Tokenize the input pair\n    inputs = tokenizer(question, article, return_tensors='pt', padding=True, truncation=True, max_length=512)\n\n    # Move inputs to the same device as the model\n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n\n    # Get model predictions (logits)\n    with torch.no_grad():\n        logits = model(input_ids=input_ids, attention_mask=attention_mask).squeeze()\n        \n    # Apply sigmoid to get probability (relevance score between 0 and 1)\n    relevance_score = sigmoid(logits).item()\n    return relevance_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T01:17:31.472726Z","iopub.execute_input":"2024-12-23T01:17:31.473040Z","iopub.status.idle":"2024-12-23T01:17:31.477883Z","shell.execute_reply.started":"2024-12-23T01:17:31.473017Z","shell.execute_reply":"2024-12-23T01:17:31.476904Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# List to store results\nresults = []\n\n# Loop through the dataset and calculate relevance for each pair\nfor index, row in df_test.iterrows():\n    question = row['question']\n    article = row['article']\n    id_ = row['Id']\n    \n    # Get the relevance score\n    relevance_score = predict_relevance(model, tokenizer, question, article, device)\n    \n    # Append the result with the id and relevance score (rounded to 4 decimals)\n    results.append({\"Id\": id_, \"relevance_score\": round(relevance_score, 4)})\n\n# Create a DataFrame from the results\nresults_df = pd.DataFrame(results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T01:17:33.270267Z","iopub.execute_input":"2024-12-23T01:17:33.270568Z","iopub.status.idle":"2024-12-23T01:17:53.818238Z","shell.execute_reply.started":"2024-12-23T01:17:33.270546Z","shell.execute_reply":"2024-12-23T01:17:53.817586Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"results_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T01:36:50.999104Z","iopub.execute_input":"2024-12-23T01:36:50.999390Z","iopub.status.idle":"2024-12-23T01:36:51.006100Z","shell.execute_reply.started":"2024-12-23T01:36:50.999369Z","shell.execute_reply":"2024-12-23T01:36:51.005230Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"results_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T01:36:47.989613Z","iopub.execute_input":"2024-12-23T01:36:47.989928Z","iopub.status.idle":"2024-12-23T01:36:47.999541Z","shell.execute_reply.started":"2024-12-23T01:36:47.989903Z","shell.execute_reply":"2024-12-23T01:36:47.998769Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"        Id  relevance_score\n0        0           0.9978\n1        1           0.9980\n2        2           0.9972\n3        3           0.0461\n4        4           0.0003\n...    ...              ...\n1056  1056           0.9990\n1057  1057           0.9323\n1058  1058           0.9987\n1059  1059           0.9980\n1060  1060           0.9983\n\n[1061 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>relevance_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.9978</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.9980</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.9972</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.0461</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0003</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>1056</td>\n      <td>0.9990</td>\n    </tr>\n    <tr>\n      <th>1057</th>\n      <td>1057</td>\n      <td>0.9323</td>\n    </tr>\n    <tr>\n      <th>1058</th>\n      <td>1058</td>\n      <td>0.9987</td>\n    </tr>\n    <tr>\n      <th>1059</th>\n      <td>1059</td>\n      <td>0.9980</td>\n    </tr>\n    <tr>\n      <th>1060</th>\n      <td>1060</td>\n      <td>0.9983</td>\n    </tr>\n  </tbody>\n</table>\n<p>1061 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":66}]}